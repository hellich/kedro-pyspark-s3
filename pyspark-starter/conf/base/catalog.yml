# Here you can define all your data sets by using simple YAML syntax.
#
# Documentation for this file format can be found in "The Data Catalog"
# Link: https://docs.kedro.org/en/latest/data/data_catalog.html
#
# We support interacting with a variety of data stores including local file systems, cloud, network and HDFS
#
# The Data Catalog supports being able to reference the same file using two different Dataset implementations
# (transcoding), templating and a way to reuse arguments that are frequently repeated. See more here:
# https://docs.kedro.org/en/latest/data/data_catalog.html
#

companies:
  type: spark.SparkDataset
  filepath: s3a://mydata/companies.csv
  file_format: csv
  load_args:
    header: True
    inferSchema: True
  save_args:
    header: True


preprocessed_companies:
  type: spark.SparkDataset
  file_format: parquet
  filepath: s3a://mydata/preprocessed_companies.parquet
  save_args:
    mode: overwrite